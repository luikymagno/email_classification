{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll introduce the theory behind the Naive Bayes learning algorithm and apply its concepts to the well known problem of classifing emails as either spam or not spam.\n",
    "\n",
    "The content of this notebook is based on the side notes of the Machine Learning course CS229 at Standford lectured by Andrew Ng.\n",
    "\n",
    "To a have better understading of the concepts behind the Naive Bayes algorithm, you should have familliarity with basic statics and more basic learning algorithms such as linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Generative Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going further in Naive Bayes, one must understand that this algorithm belongs to a larger class of algorithms called Generative Learning Algorithms. To make it clear, we will firstly compare it with the Discriminative Learning Algorithm class in which linear regression and logistic regression belong.\n",
    "\n",
    "To begin our discussion, in Discriminative Learning Algorithms our goal is to learn $p(y|x)$ directly where, for instance, $y \\in I\\!R$ is the target variable and $x \\in I\\!R^d$ is the vector of features. One option to learn this relation given a training set is by finding the maximum of the log likelihood using gradient descent.\n",
    "\n",
    "However, instead of modelling $p(y|x)$ one could model $p(x|y)$ and find the relation $p(y|x)$ indirectly by using the Bayes' rule which states: $p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$. The learning algorithms which use this approach are called Generative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this generative algorithm the features are discrete valued and our goal is to perform a classification. To simplify the understadind of how it works, we will focus on the spam filter problem in which we want to create a model that takes an email, i.e. the words in the email's body, and tell us whether this email is a spam or not. In other other words, we will deal with a text classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Choosing a representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we are given a set of emails with their corresponding labels (spam or not spam). Then, we will represent an email as a vector whose length is equal to the number of distinct words considering the contents of each email in the given set, which we will call here the vocabulary.  \n",
    "Our vector looks like it:\n",
    "$$x = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\vdots \\\\\n",
    "x_d \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Where the j-th represents whether the j-th word in the vocabulary. As an example, if the email contains the word \"buy\" and this word is the 50-th position in the vobulary, then the vector representing this email will have in its 50-th position the value 1. Besides, the target variable will read 1 when the email is a spam and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Modelling the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build a generative model, which means choosing how to models $p(x|y)$. Since we are dealing with discrete values, we can model $p(x|y)$ with a multinomial distribution. However, if we were to do that now, each possible combination of our vector $x$ would have an associated probability, hence our model would have $2^v - 1$ parameters where $d$ is the number of words in the vocabulary, meaning our model would have too many parameters.\n",
    "\n",
    "To solve this problem, we will make a very strong assumption on how the $x_is$ are related. That being said, we assume that the $x_is$ are conditionally independent given y. This assumption is called the Naive Bayes assumption, from where the algorithm's name. For instance, this assumption says that if $y=1$ then knowing that the word \"buy\" is present in the email's content has no effects on the belifs about whether the word \"price\" is present or not in the email's content.\n",
    "\n",
    "With this in mind, we verify that:\n",
    "\n",
    "$p(x_1, ..., x_v|y) = p(x_1|y)p(x_2|y, x_1)p(x_3|y, x_1, x_2)...p(x_v|y, x_1, ..., x_{v-1}) = p(x_1|y)p(x_2|y)...p(x_v|y) = \\Pi_{j=1}^dp(x_j|y)$\n",
    "\n",
    "Having said that, we now will be able to find a model with less parameters due to the Naive Bayes assumption by maximizing the joint likelihood* of the data:\n",
    "\n",
    "*. We do not use the conditional likelihood, because the joint one provided us with some useful proporties for this case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Applying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will use to build the model can be found at: http://www2.aueb.gr/users/ion/data/enron-spam/. The data provided there have the contents of emails separated in two folders which are \"spam\" and \"ham\". Then, we will pre process the data to put it in the format defined in the section 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import random as rd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Set random seed\n",
    "rd.seed(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples: int = 800\n",
    "columns: list[str] = [\"is_spam\", \"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13687/3059246836.py:20: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n",
      "  ham_df = pd.concat([ham_df, row_df], ignore_index=True, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the ham dataset: (800, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: misc . questions\\nhhere are some ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: midlothian forecast\\n- - - - - - - - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: calpine daily gas nomination\\n- hidal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: re : feedback monitor error - meter 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Subject: 98 - 1600 &amp; 98 - 6725 needing k ' s\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam                                            content\n",
       "0      0.0  Subject: misc . questions\\nhhere are some ques...\n",
       "1      0.0  Subject: midlothian forecast\\n- - - - - - - - ...\n",
       "2      0.0  Subject: calpine daily gas nomination\\n- hidal...\n",
       "3      0.0  Subject: re : feedback monitor error - meter 9...\n",
       "4      0.0  Subject: 98 - 1600 & 98 - 6725 needing k ' s\\n..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_df: pd.DataFrame = pd.DataFrame({\n",
    "    columns[0]: pd.Series(dtype=\"bool\"),\n",
    "    columns[1]: pd.Series(dtype=\"int\"),\n",
    "})\n",
    "\n",
    "# Go through the ham files and load the their data\n",
    "ham_dir_path: str = \"enron1/ham/\"\n",
    "for file_name in os.listdir(ham_dir_path):\n",
    "\n",
    "    with open(ham_dir_path+file_name, \"r\") as f:\n",
    "        try:\n",
    "            email_content: str = f.read()\n",
    "        except UnicodeDecodeError as e:\n",
    "            continue # Ignore files that cannot be decoded for now\n",
    "\n",
    "    row_df: pd.DataFrame = pd.DataFrame({\n",
    "        columns[0]: [0.0],\n",
    "        columns[1]: [email_content],\n",
    "    })\n",
    "    ham_df = pd.concat([ham_df, row_df], ignore_index=True, axis=0)\n",
    "\n",
    "    if ham_df.shape[0] == nb_samples: break\n",
    "\n",
    "print(f\"Shape of the ham dataset: {ham_df.shape}\")\n",
    "ham_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13687/3935112127.py:20: FutureWarning: Behavior when concatenating bool-dtype and numeric-dtype arrays is deprecated; in a future version these will cast to object dtype (instead of coercing bools to numeric values). To retain the old behavior, explicitly cast bool-dtype arrays to numeric dtype.\n",
      "  spam_df = pd.concat([spam_df, row_df], ignore_index=True, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the spam dataset: (800, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: cardiology , radiology , 7 , 000 seni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: hi there buddy - feel the vitality\\nf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: \\n9\\nreceived : from 55 . 240 . 132 ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: adipren 720 - find out the latest fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Subject: paliourg , super offers for meedicati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam                                            content\n",
       "0      1.0  Subject: cardiology , radiology , 7 , 000 seni...\n",
       "1      1.0  Subject: hi there buddy - feel the vitality\\nf...\n",
       "2      1.0  Subject: \\n9\\nreceived : from 55 . 240 . 132 ....\n",
       "3      1.0  Subject: adipren 720 - find out the latest fac...\n",
       "4      1.0  Subject: paliourg , super offers for meedicati..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df: pd.DataFrame = pd.DataFrame({\n",
    "    columns[0]: pd.Series(dtype=\"bool\"),\n",
    "    columns[1]: pd.Series(dtype=\"int\"),\n",
    "})\n",
    "\n",
    "# Go through the spam files and load the their data\n",
    "spam_dir_path: str = \"enron1/spam/\"\n",
    "for file_name in os.listdir(spam_dir_path):\n",
    "\n",
    "    with open(spam_dir_path+file_name, \"r\") as f:\n",
    "        try:\n",
    "            email_content: str = f.read()\n",
    "        except UnicodeDecodeError as e:\n",
    "            continue # Ignore files that cannot be decoded for now\n",
    "\n",
    "    row_df: pd.DataFrame = pd.DataFrame({\n",
    "        columns[0]: [1.0],\n",
    "        columns[1]: [email_content],\n",
    "    })\n",
    "    spam_df = pd.concat([spam_df, row_df], ignore_index=True, axis=0)\n",
    "\n",
    "    if spam_df.shape[0] == nb_samples: break\n",
    "\n",
    "print(f\"Shape of the spam dataset: {spam_df.shape}\")\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df: pd.DataFrame = pd.concat([ham_df, spam_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>subject: misc . questions hhere are some quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>subject: midlothi fecast - - - - - - - - - - -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>subject: calpine daily gas nomination - hidalg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>subject: re : feedback monir err - meter 98413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>subject: 98 - 1600 &amp; 98 - 6725 needing k ' s d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam                                            content\n",
       "0      0.0  subject: misc . questions hhere are some quest...\n",
       "1      0.0  subject: midlothi fecast - - - - - - - - - - -...\n",
       "2      0.0  subject: calpine daily gas nomination - hidalg...\n",
       "3      0.0  subject: re : feedback monir err - meter 98413...\n",
       "4      0.0  subject: 98 - 1600 & 98 - 6725 needing k ' s d..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Clean the data #####\n",
    "\n",
    "# Some words doesn't give any further information to the model since they are not related to whether an email is a spam or not\n",
    "# since they will be present in both cases without distinction\n",
    "# e.g. 'the', 'and', ...\n",
    "words_to_ignore: list[str] = [\"the\", \"a\", \"an\", \"and\", \"to\", \"or\"]\n",
    "\n",
    "def clean_text(row: pd.Series, words_to_ignore: list[str]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Create a column with a list of words contained in the email's content\n",
    "    Remove unuseful words\n",
    "    The words are separated by the special character sequence '||'\n",
    "    \"\"\"\n",
    "\n",
    "    normalized_content: str = \" \".join(unidecode.unidecode(row[\"content\"].lower()).split())\n",
    "    words_to_ignore_formatted: str = f\"{words_to_ignore[0]}\"\n",
    "    for word in words_to_ignore[1:]:\n",
    "        words_to_ignore_formatted += f\"{word}|\"\n",
    "    row[\"content\"] = re.sub(r\"[-\\d:;\\./,'\\{\\}\\(\\)]\"+words_to_ignore_formatted, \"\", normalized_content)\n",
    "    return row\n",
    "\n",
    "email_df = email_df.apply(lambda row: clean_text(row=row, words_to_ignore=words_to_ignore), axis=1)\n",
    "email_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Tranform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000000</th>\n",
       "      <th>000000000049773</th>\n",
       "      <th>000080</th>\n",
       "      <th>0001</th>\n",
       "      <th>00018</th>\n",
       "      <th>0004</th>\n",
       "      <th>0005</th>\n",
       "      <th>...</th>\n",
       "      <th>zxklh</th>\n",
       "      <th>zxzmcnbf</th>\n",
       "      <th>zyb</th>\n",
       "      <th>zyjvit</th>\n",
       "      <th>zykfe</th>\n",
       "      <th>zyl</th>\n",
       "      <th>zynve</th>\n",
       "      <th>zyrtec</th>\n",
       "      <th>zzezrjok</th>\n",
       "      <th>zzso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  000000  000000000049773  000080  0001  00018  0004  0005  \\\n",
       "0   0    0     0       0                0       0     0      0     0     0   \n",
       "1   0    2     0       0                0       0     0      0     0     0   \n",
       "2   0    0     0       0                0       0     0      0     0     0   \n",
       "3   0    1     0       0                0       0     0      0     0     0   \n",
       "4   0    0     0       0                0       0     0      0     0     0   \n",
       "\n",
       "   ...  zxklh  zxzmcnbf  zyb  zyjvit  zykfe  zyl  zynve  zyrtec  zzezrjok  \\\n",
       "0  ...      0         0    0       0      0    0      0       0         0   \n",
       "1  ...      0         0    0       0      0    0      0       0         0   \n",
       "2  ...      0         0    0       0      0    0      0       0         0   \n",
       "3  ...      0         0    0       0      0    0      0       0         0   \n",
       "4  ...      0         0    0       0      0    0      0       0         0   \n",
       "\n",
       "   zzso  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 30314 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer: CountVectorizer = CountVectorizer()\n",
    "\n",
    "# Transform the features\n",
    "vectorized_features = vectorizer.fit_transform(email_df[\"content\"].values).toarray()\n",
    "vectorized_features_df: pd.DataFrame = pd.DataFrame(vectorized_features, columns=vectorizer.get_feature_names_out())\n",
    "vectorized_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam\n",
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the targets\n",
    "targets_df: pd.DataFrame = email_df[[\"is_spam\"]]\n",
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    vectorized_features_df,\n",
    "    targets_df[\"is_spam\"],\n",
    "    test_size=0.3,\n",
    "    train_size=0.7,\n",
    "    random_state=9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.005)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomial_nb_model: MultinomialNB = MultinomialNB(alpha=0.005)\n",
    "multinomial_nb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.41666666666667%\n"
     ]
    }
   ],
   "source": [
    "predictions = multinomial_nb_model.predict(x_test)\n",
    "print(f\"Accuracy: {100 * sum(predictions == y_test) / len(predictions)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://binitaregmi.medium.com/spam-classification-using-naive-bayes-algorithm-3e263061a3b0  \n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f813e25c188beed027c3b41c9ad4546e416ab757a140cf9e2c02d46c36eafa2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('email_classification_391')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
